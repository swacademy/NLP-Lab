{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7fHL3ONZ55I-"
   },
   "source": [
    "# Lab5. Validation\n",
    "### Cross Validation\n",
    "+ The Set of Train, Valid, Test \n",
    "+ k-Fold with Stratify\n",
    "+ Cross Validation Score\n",
    "\n",
    "## Parameter Tuning\n",
    "+ Grid Search\n",
    "+ Random Search\n",
    "\n",
    "## Ensemble\n",
    "+ Voting Ensemble\n",
    "+ Stacking, Average Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dng6Tegg6eNc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "adult_path = join('sample_data', 'adult_data.csv')\n",
    "column_path = join('sample_data', 'adult_names.txt')\n",
    "\n",
    "adult_columns = list()\n",
    "for l in open(column_path):\n",
    "    adult_columns = l.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(adult_path, names = adult_columns)\n",
    "label = data['income']\n",
    "\n",
    "del data['income']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas get_dummies 함수를 사용해 범주형 변수를 One-Hot Encoding하고, label data를 0,1 로 변경한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data)\n",
    "label = label.map(lambda x : 0 if x =='>50K' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "### 1. Train, Valid, Test Set\n",
    "- 훈련, 검증, 테스트 데이터라고 부르는 3가지를 설명한다.\n",
    "* Train Data : 모델을 학습하는데 사용하는 데이터 (모델이 알고 있는 학습할 데이터)\n",
    "* Valid Data : 학습한 모델의 성능을 검증하는 데이터 (모델이 모르는 학습하지 않을 데이터, 모델 검증에 사용하는 데이터)\n",
    "* Test Data : 학습한 모델로 예측할 데이터 (모델이 모르는 예측할 데이터)\n",
    "\n",
    "<img src='./img/train_val_test.png' style='height : 500px' >\n",
    "\n",
    "\n",
    "- Machine Learning에서 Validation 데이터가 왜 필요한지에 대한 부분은 참조 링크를 남겨두었으니 확인하시면 좋겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ones : {:.2f}%'.format((np.sum(label==1, axis=0)/len(data))*100))\n",
    "print('zeros : {:.2f}%'.format((np.sum(label==0, axis=0)/len(data))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# (Train, Valid), Test 분할\n",
    "x, x_test, y, y_test = train_test_split(data, label, test_size=0.2, stratify=label, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Valid 분할\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr = LogisticRegression(random_state=2019)\n",
    "# Train 데이터로 학습\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid 데이터로 검증\n",
    "y_pred_val = lr.predict(x_valid)\n",
    "print('로지스틱 회귀 검증 데이터 정확도 :  {:.2f}%'.format(accuracy_score(y_valid, y_pred_val)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 데이터로 모델 평가\n",
    "y_pred = lr.predict(x_test)\n",
    "print('로지스틱 회귀 테스트 데이터 정확도 : {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. k-fold with stratify\n",
    "- k-fold는 data를 k개로 쪼개는 것을 말한다.\n",
    "- 일반적으로 Cross Validation에서 사용되며, Dataset을 k개로 쪼개어 k-1개로 모델을 학습하고, 1개로 모델을 검증한다.\n",
    "- k개로 데이터를 쪼개면, 모든 fold에 대해(하나의 fold를 선택하여) 검증하는 방식으로 k번 다른 Dataset으로 학습한 모델을 검증할 수 있다.\n",
    "\n",
    "![kfold](./img/kfold.png)\n",
    "\n",
    "#### Stratify, 계층적 k-fold는 무엇인가?\n",
    "- k-fold는 데이터의 정렬 유무와 분류할 클래스의 비율에 상관없이 순서대로 데이터를 분할하는 특징이 있다.\n",
    "- 하지만, 분류할 클래스의 비율이 다르다면 어떻게 될까? \n",
    "- 그런 경우에는, 각 fold가 학습 Dataset을 대표한다고 말하기 어려워진다.\n",
    "- 한 fold에 특정 클래스가 많이 나올수도, 적게 나올수도 있기 때문이다. \n",
    "- Stratified k-fold는 그러한 문제점을 해결하기 위해 제안되었다.\n",
    "- k개의 fold도 분할한 이후에도, 전체 훈련 데이터의 클래스 비율과 각 fold가 가지고 있는 클래스의 비율을 맞추어 준다는 점이 기존의 k-fold와의 다른 특징이다. \n",
    "\n",
    "##### k-fold\n",
    "![kfold_example](./img/kfold_example.png)\n",
    "\n",
    "##### Stratified k-fold\n",
    "![stratified_kfold_example](./img/stratified_kfold_example.png)\n",
    "\n",
    "- k-fold 실습을 위해 iris 데이터를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "kf_data = iris.data\n",
    "kf_label = iris.target\n",
    "kf_columns = iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_data = pd.DataFrame(kf_data, columns = kf_columns)\n",
    "kf_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-Fold\n",
    "- k-fold는 말 그대로 데이터를 k개로 나눈다.\n",
    "- k의 개수를 조절하여 몇개의 fold를 만들지 결정할 수 있다.\n",
    "\n",
    "- k-fold는 sklearn의 model_selection 패키지에 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (trn_idx, val_idx) in enumerate(kf.split(kf_data.values, kf_label)) :\n",
    "    trn_data, trn_label = kf_data.values[trn_idx, :], kf_label[trn_idx]\n",
    "    val_data, val_label = kf_data.values[val_idx, :], kf_label[val_idx]\n",
    "    \n",
    "    print('{} Fold, trn label\\n {}'.format(i, trn_label))\n",
    "    print('{} Fold, val label\\n {}\\n'.format(i, val_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stratify k-Fold\n",
    "\n",
    "- Stratified k-fold는 sklearn의 model_selection package에 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (trn_idx, val_idx) in enumerate(skf.split(kf_data, kf_label)) :\n",
    "    trn_data, trn_label = kf_data.values[trn_idx,:], kf_label[trn_idx]\n",
    "    val_data, val_label = kf_data.values[val_idx,:], kf_label[val_idx]\n",
    "    \n",
    "    print('{} Fold, trn label\\n {}'.format(i, trn_label))\n",
    "    print('{} Fold, val label\\n {}\\n'.format(i, val_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation 해보기\n",
    "- Stratified k-fold를 이용해 Cross Validation을 진행해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "val_scores = list()\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(kf_data, kf_label)) :\n",
    "    trn_data, trn_label = kf_data.values[trn_idx, :], kf_label[trn_idx]\n",
    "    val_data, val_label = kf_data.values[val_idx, :], kf_label[val_idx]\n",
    "    \n",
    "    # 모델 정의\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=2019)\n",
    "    \n",
    "    # 모델 학습\n",
    "    clf.fit(trn_data, trn_label)\n",
    "\n",
    "    # 훈련, 검증 데이터 정확도 확인\n",
    "    trn_acc = clf.score(trn_data, trn_label)*100\n",
    "    val_acc = clf.score(val_data, val_label)*100\n",
    "    print('{} Fold, train Accuracy : {:.2f}%, validation Accuracy : {:.2f}%'.format(i, trn_acc, val_acc))\n",
    "    \n",
    "    val_scores.append(val_acc)\n",
    "\n",
    "# 교차 검증 정확도 평균 계산하기\n",
    "print('Cross Validation Score : {:.2f}%'.format(np.mean(val_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation Score\n",
    "- 방금 전 반복문을 사용해 Cross Validation을 진행해 봤다.\n",
    "- 그런데 Sklearn에는 한번에 k-fold Cross Validation Score를 계산하는 cross_val_score 함수를 제공한다. \n",
    "- Parameter로 cv에 숫자를 전달하면, 그 숫자 만큼의 fold를 만들어 Cross Validation(CV)을 진행하고, kfold 객체를 전달하면 해당 객체에 맞게 데이터를 분할하여 CV Score를 계산한다.\n",
    "- cross_val_score 함수는 fold 개수대로 Score를 반환하며, 해당 스코어들의 평균을 계산해 모델의 성능을 가늠해볼 수 있다.\n",
    "\n",
    "* 기본적으로 cross_val_score 함수는 입력 Label 값이 클래스로 나누어진 분류 모델인 경우 StratifiedKFold를 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자로 전달하는 경우\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=2019)\n",
    "print('랜덤 포레스트 k-Fold CV Score(Acc) : {}'.format(np.mean(cross_val_score(rf, kf_data, kf_label, cv=skf))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fold 객체를 전달하는 경우\n",
    "- print('Random Forest k-Fold CV Score(Acc) : {:.2f}%'.format()\n",
    "- print('Random Forest Stratify k-Fold CV Score(Acc) : {:.2f}%'.format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning\n",
    "### GridSearch \n",
    "- 모델에는 여러가지 parameter가 들어간다.\n",
    "- SVM의 경우 Soft, Hard 마진의 정도를 결정하는 'C' 커널 함수를 결정하는 'kernel', 특정 커널에서 얼마나 세세하게 볼것인지를 결정하는 'gamma' 등.\n",
    "- Parameter를 어떻게 결정하느냐에 따라 모델이 잘 학습하거나 잘 학습하지 못하는 경우가 발생할 수 있다.\n",
    "- Sklearn에서 가장 쉽게 제공하는 Parameter Tuning 함수로 GridSearchCV 라는 함수가 있다. \n",
    "- 해당 함수에 각 Parameter에 사용할 수치 list를 전달하면, 해당 함수는 parameter들의 조합을 모두 시도해보며, 가장 좋은 성능의 Parameter를 찾게 된다. \n",
    "\n",
    "- 간단히 GridSearchCV 함수를 사용해 Random Forest의 n_estimator, max_depth parameter 중 가장 좋은 parameter 조합을 찾아본다.\n",
    "- GridSearchCV 함수는 Sklearn의 model_selection package에 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 모델 정의 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators' : [50, 100, 150, 200],\n",
    "          'max_depth' : [5, 10 ,15, 20],\n",
    "          'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), params, cv=skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(kf_data, kf_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3,4) 예측 및 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GridSearchCV best score : {:.2f}%, best_params : {}'.format(clf.best_score_*100, clf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-Optimize\n",
    "- GridSearch의 단점은 사용자가 직접 Parameter에 들어갈 값들의 list를 지정해주어야 한다는 단점이 있다.\n",
    "- Sklearn library 내에 존재하지는 않지만, Scikit-Optimize(이하, skopt)라는 library를 간단히 소개하려고 한다.\n",
    "- skopt는 각 Parameter에 들어갈 값들의 최대, 최소 범위를 결정해주고 파라미터 값의 분포 Scale을 결정해주어 Parameter tuning을 자동화 시켜주는 library이다.\n",
    "- 아래 참조 링크에 Skopt 링크가 있으니 확인해보면 좋겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "- 개인적으로 Ensemble은 Machine Learning의 꽃이라고 생각한다. \n",
    "- 단일 모델로 좋은 성능을 이끄는 것도 중요하지만, 서로 다른 모델의 다양성을 고려하여 결과를 이끌어내는 Ensemble은 응용할 수 있는 방법이 매우 많다. \n",
    "- 그 중 대표적인 3가지 Ensemble에 대해 실습하고 배워보도록 한다. \n",
    "\n",
    "### 1. Voting Ensemble\n",
    "- 이름에서 알 수 있듯이 각자의 모델이 투표를 하여 클래스를 선택하는 방식의 Emsemble이다.\n",
    "- Voting Ensemble은 Sklearn 자체적으로 모델로써 지원을 하며, 사용하기도 매우 쉽다. \n",
    "\n",
    "- 다시 Adult Dataset으로 돌아와 Ensemble을 통해 기존 단일 모델보다 좋은 결과를 얻어보도록 하자.\n",
    "\n",
    "- Voting Classifier는 Sklearn의 ensemble package에 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 모델 불러오기 및 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "clfs = [('LR', LogisticRegression()), ('RF', RandomForestClassifier(max_depth=5)), ('MLP', MLPClassifier()) ]\n",
    "\n",
    "vote_clf = VotingClassifier(clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cross Validation Acc : {:.2f}%'.format(vote_clf.score(x_valid, y_valid)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 결과 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = vote_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Voting Ensemble Acc : {:.2f}%'.format(vote_clf.score(x_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bagging, Average Blending\n",
    "- Emsemble 기법 중 Kaggle에서 가장 많이 사용되는 기법이면서 쉬운 기법이다.\n",
    "- Average Blending에서 회귀의 경우 각 모델들이 예측한 결과 값을 n으로 나누어 합친다.\n",
    "- 분류의 경우에는 각 클래스에 해당하는 확률을 n으로 나누어 합치고, 그 중 가장 높은 확률 값을 갖는 클래스를 택하는 방식이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 모델에서의 Random Forest 성능\n",
    "clf = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=2019)\n",
    "clf.fit(x_train, y_train)\n",
    "print('Single Random Forest Acc : {:.2f}%'.format(clf.score(x_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores = list()\n",
    "\n",
    "y_pred = np.zeros_like(y_test, dtype=np.float)\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(x, y)) :\n",
    "    trn_data, trn_label = x.values[trn_idx, :], y.values[trn_idx]\n",
    "    val_data, val_label = x.values[val_idx, :], y.values[val_idx]\n",
    "    \n",
    "    # 모델 정의\n",
    "    clf = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=2019)\n",
    "    \n",
    "    # 모델 학습\n",
    "    clf.fit(trn_data, trn_label)\n",
    "    trn_acc = clf.score(trn_data, trn_label)*100\n",
    "    val_acc = clf.score(val_data, val_label)*100\n",
    "    print('{} Fold, train Accuracy : {:.2f}%, validation Accuracy : {:.2f}%'.format(i, trn_acc, val_acc))\n",
    "    \n",
    "    val_scores.append(val_acc)\n",
    "    y_pred += (clf.predict_proba(x_test)[:, 1] / skf.n_splits)\n",
    "    \n",
    "# Mean Validation Score\n",
    "print('Cross Validation Score : {:.2f}%'.format(np.mean(val_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확률을 이진 라벨로 변경해줍니다.\n",
    "y_pred = [0 if y < 0.5 else 1 for y in y_pred]\n",
    "print('Average Blending Acc : {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "- Validation 데이터가 필요한 이유 : https://3months.tistory.com/118\n",
    "- Sklearn, KFold : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "- Sklearn, StratifedKFold : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold\n",
    "- Sklearn, Compare with KFold, StratifedKFold : https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py\n",
    "- Sklearn, Cross Validation Score : https://www.google.com/url?q=http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html&sa=U&ved=0ahUKEwiGxeHhqubhAhUKV7wKHbFhDrcQFggEMAA&client=internal-uds-cse&cx=016639176250731907682:tjtqbvtvij0&usg=AOvVaw0rIHEJ1ltDaghFv1bvPeRO\n",
    "- Sklearn, GridSearchCV : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "- Sklearn, Voting Classifier : https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
    "- Scikit-Optimize, Documentation : https://scikit-optimize.github.io "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_05) Model Validation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
